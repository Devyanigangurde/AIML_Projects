{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devyanigangurde/AIML_Projects/blob/main/MNIST_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mca_WkgHHyk2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m5PCIofHyk6"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.keras.utils as tku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HLQBsMCHyk8",
        "outputId": "b83b4e3c-d8b7-492d-da50-c7d39bcc0f19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JPPXp_XHyk-",
        "outputId": "2c2a2f14-456c-488f-cfa3-cbbcf8a0b5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 37340 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('datasets/MNIST/training_set',\n",
        "                                                 target_size = (28, 28),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCv1hY6jHyk-",
        "outputId": "47675a5b-9afb-40d9-dd61-d7d39fd8c956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4660 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_set = train_datagen.flow_from_directory('datasets/MNIST/test_set',\n",
        "                                                 target_size = (28, 28),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_fb0jr9Hyk_"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_17i7i-HylA"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[28, 28, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE8D9J1oHylB"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3btLO5lYHylC"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThjmOYF0HylD"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcFDSW9QHylE"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnkZeXMSHylE"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWUltP1BHylF"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HOqXzz9HylF",
        "outputId": "8c01ccde-c634-4e64-8c87-8d154e7727b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1167/1167 [==============================] - 82s 69ms/step - loss: 0.6410 - accuracy: 0.7932 - val_loss: 0.1604 - val_accuracy: 0.9481\n",
            "Epoch 2/20\n",
            "1167/1167 [==============================] - 96s 83ms/step - loss: 0.1540 - accuracy: 0.9509 - val_loss: 0.0991 - val_accuracy: 0.9695\n",
            "Epoch 3/20\n",
            "1167/1167 [==============================] - 104s 90ms/step - loss: 0.1028 - accuracy: 0.9670 - val_loss: 0.0802 - val_accuracy: 0.9749\n",
            "Epoch 4/20\n",
            "1167/1167 [==============================] - 64s 55ms/step - loss: 0.0848 - accuracy: 0.9740 - val_loss: 0.0765 - val_accuracy: 0.9770\n",
            "Epoch 5/20\n",
            "1167/1167 [==============================] - 66s 57ms/step - loss: 0.0724 - accuracy: 0.9765 - val_loss: 0.0843 - val_accuracy: 0.9723\n",
            "Epoch 6/20\n",
            "1167/1167 [==============================] - 61s 52ms/step - loss: 0.0625 - accuracy: 0.9813 - val_loss: 0.0629 - val_accuracy: 0.9803\n",
            "Epoch 7/20\n",
            "1167/1167 [==============================] - 68s 58ms/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 0.0647 - val_accuracy: 0.9805\n",
            "Epoch 8/20\n",
            "1167/1167 [==============================] - 46s 39ms/step - loss: 0.0559 - accuracy: 0.9827 - val_loss: 0.0688 - val_accuracy: 0.9790\n",
            "Epoch 9/20\n",
            "1167/1167 [==============================] - 51s 44ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.0674 - val_accuracy: 0.9783\n",
            "Epoch 10/20\n",
            "1167/1167 [==============================] - 104s 89ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 0.0500 - val_accuracy: 0.9828\n",
            "Epoch 11/20\n",
            "1167/1167 [==============================] - 392s 336ms/step - loss: 0.0412 - accuracy: 0.9859 - val_loss: 0.0603 - val_accuracy: 0.9815\n",
            "Epoch 12/20\n",
            "1167/1167 [==============================] - 43s 37ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0613 - val_accuracy: 0.9811\n",
            "Epoch 13/20\n",
            "1167/1167 [==============================] - 29s 25ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0627 - val_accuracy: 0.9815\n",
            "Epoch 14/20\n",
            "1167/1167 [==============================] - 44s 38ms/step - loss: 0.0379 - accuracy: 0.9878 - val_loss: 0.0459 - val_accuracy: 0.9850\n",
            "Epoch 15/20\n",
            "1167/1167 [==============================] - 48s 41ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 0.0591 - val_accuracy: 0.9809\n",
            "Epoch 16/20\n",
            "1167/1167 [==============================] - 54s 46ms/step - loss: 0.0357 - accuracy: 0.9877 - val_loss: 0.0500 - val_accuracy: 0.9845\n",
            "Epoch 17/20\n",
            "1167/1167 [==============================] - 37s 32ms/step - loss: 0.0285 - accuracy: 0.9902 - val_loss: 0.0617 - val_accuracy: 0.9811\n",
            "Epoch 18/20\n",
            "1167/1167 [==============================] - 36s 31ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.0636 - val_accuracy: 0.9830\n",
            "Epoch 19/20\n",
            "1167/1167 [==============================] - 52s 44ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0582 - val_accuracy: 0.9848\n",
            "Epoch 20/20\n",
            "1167/1167 [==============================] - 41s 35ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.0479 - val_accuracy: 0.9841\n"
          ]
        }
      ],
      "source": [
        "trained_model = cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hm3To8aHylG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('datasets/MNIST/single_prediction/img_52.jpg', target_size = (28, 28))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "results = (cnn.predict(test_image))\n",
        "training_set.class_indices\n",
        "if results[0][0] == 1:\n",
        "  prediction = 'Zero'\n",
        "elif results[0][1] == 1:\n",
        "  prediction = 'One'\n",
        "elif results[0][2] == 1:\n",
        "  prediction = 'Two'\n",
        "elif results[0][3] == 1:\n",
        "  prediction = 'Three'\n",
        "elif results[0][4] == 1:\n",
        "  prediction = 'Four'\n",
        "elif results[0][5] == 1:\n",
        "  prediction = 'Five'\n",
        "elif results[0][6] == 1:\n",
        "  prediction = 'Six'\n",
        "elif results[0][7] == 1:\n",
        "  prediction = 'Seven'\n",
        "elif results[0][8] == 1:\n",
        "  prediction = 'Eight'\n",
        "else:\n",
        "  prediction = 'Nine'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsmK0zO4HylG",
        "outputId": "8f50916c-2b73-4f9b-ec0c-4bc7d9952b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDlEIOFwHylH",
        "outputId": "d68af17c-ca2e-45fa-b480-febaada6b05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eight\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}